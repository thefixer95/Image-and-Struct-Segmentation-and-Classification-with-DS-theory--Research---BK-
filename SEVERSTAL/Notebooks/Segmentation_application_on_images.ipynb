{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image, ImageOps\n",
    "import PIL\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import exposure\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "import copy\n",
    "import cv2\n",
    "\n",
    "# import sklearn as sk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, smart_resize, ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.utils import get_file, plot_model, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT ALL LAYERS AND KERAS/TENSORFLOW PARAMS\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import StringLookup, CategoryEncoding, GlobalMaxPooling2D, Rescaling, SeparableConv2D, BatchNormalization, Conv2D, MaxPool2D, Activation, Dropout, Dense, Flatten, Input, Concatenate, Add, AveragePooling2D, GlobalAveragePooling2D, AveragePooling1D, Reshape\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.activations import relu,leaky_relu\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "import keras_ocr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, log_loss, confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n",
      "Tensor Flow Version: 2.8.0\n",
      "Keras Version: 2.8.0\n",
      "Pandas 1.3.5\n",
      "Keras Version: 1.22.3\n",
      "\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Keras Version: {np.__version__}\")\n",
    "print()\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 19 17:45:14 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.77       Driver Version: 512.77       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   50C    P8    41W / 350W |   3161MiB / 12288MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1108    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      1572    C+G   ...210.47\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      2924    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      4756    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8284    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      8580    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A      8616    C+G   ...210.47\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      9948    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10016    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11192    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     11724    C+G   ...8bbwe\\Notepad\\Notepad.exe    N/A      |\n",
      "|    0   N/A  N/A     12624    C+G   ...oot\\Office16\\POWERPNT.EXE    N/A      |\n",
      "|    0   N/A  N/A     14260    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     16440    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     18772    C+G   ...root\\Office16\\OUTLOOK.EXE    N/A      |\n",
      "|    0   N/A  N/A     20776    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     21248    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A     24300    C+G   ...3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../E-CNN-classifier-main/libs')\n",
    "import ds_layer #Dempster-Shafer layer\n",
    "import utility_layer_train #Utility layer for training\n",
    "import utility_layer_test #Utility layer for training\n",
    "import AU_imprecision #Metric average utility for set-valued classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTrainImgs = Path('../DB/train_images/')\n",
    "cvsPath = Path('../DB/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointPath = Path('../Outputs/CNN/CHECKPOINTS/')\n",
    "graphPath = Path('../Outputs/CNN/GRAPHS/')\n",
    "pathSavedModel = Path('../Outputs/CNN/MODELS-PB/')\n",
    "plotpath = Path('../Outputs/CNN/PLTS/')\n",
    "evalspath = Path('../Outputs/CNN/EVALUATIONS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointPath.mkdir(parents=True, exist_ok=True)\n",
    "graphPath.mkdir(parents=True, exist_ok=True)\n",
    "pathSavedModel.mkdir(parents=True, exist_ok=True)\n",
    "plotpath.mkdir(parents=True, exist_ok=True)\n",
    "evalspath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_SIZE = [1600,256] #original size\n",
    "IMAGE_SIZE = [256,1600] #original size\n",
    "# IMAGE_SIZE = [256,256]\n",
    "IMAGE_RESIZE = [256,800]\n",
    "CLASS_NAMES = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAndSaveGraphs(pathWsave,nameOfModelGraph, history, Metrics, saveit = True, dpi = 300):\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model '+nameOfModelGraph+ ' loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation-HKonly'], loc='upper left')\n",
    "    if saveit:\n",
    "        plt.savefig(Path(pathWsave) / Path(nameOfModelGraph + '_loss.png'),dpi=dpi)\n",
    "    plt.show()\n",
    "\n",
    "    for met in Metrics:\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history[met.name])\n",
    "        plt.plot(history.history['val_'+met.name])\n",
    "        plt.title('model '+nameOfModelGraph+ met.name)\n",
    "        plt.ylabel(met.name)\n",
    "        # plt.plot(history.history[met])\n",
    "        # plt.plot(history.history['val_'+met])\n",
    "        # plt.title('model '+nameOfModelGraph+ met)\n",
    "        # plt.ylabel(met)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        if saveit:\n",
    "            plt.savefig(Path(pathWsave) / Path(nameOfModelGraph + met.name + '.png'),dpi=dpi)\n",
    "            # plt.savefig(Path(pathWsave) / Path(nameOfModelGraph + met + '.png'),dpi=dpi)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPNGtoArray(paths,basePath, outSize = IMAGE_SIZE, resize = True):\n",
    "    imgs = []\n",
    "    for p in tqdm(paths):\n",
    "        p = Path(p)\n",
    "        # print(p)\n",
    "        # fullPath = Path(str(basePath) + str(p))\n",
    "        fullPath = basePath / p\n",
    "        # print(basePath)\n",
    "        # print(fullPath)\n",
    "        if resize:\n",
    "            img = load_img(fullPath,target_size=(outSize[0],outSize[1]))\n",
    "        else:\n",
    "            img = load_img(fullPath)\n",
    "        imgs.append(img)\n",
    "    imgs = np.array([np.array(fname) for fname in imgs])  #transform each element of list in numpy array    \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all our data\n",
    "SevDB = pd.read_csv(cvsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007a71bf.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a4bcdd.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>37607 3 37858 8 38108 14 38359 20 38610 25 388...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000f6bf48.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014fce06.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>229501 11 229741 33 229981 55 230221 77 230468...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg        1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0007a71bf.jpg        3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
       "2  000a4bcdd.jpg        1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
       "3  000f6bf48.jpg        4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
       "4  0014fce06.jpg        3  229501 11 229741 33 229981 55 230221 77 230468..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SevDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for x in range(len(CLASS_NAMES)):\n",
    "    mapping[CLASS_NAMES[x]] = x\n",
    "\n",
    "\n",
    "\n",
    "takename = copy.deepcopy(SevDB['ClassId'])\n",
    "for x in range(len(takename)):\n",
    "    takename[x] = mapping[takename[x]]\n",
    "\n",
    "\n",
    "one_h_enc = to_categorical(takename)\n",
    "\n",
    "i = 0\n",
    "for n in CLASS_NAMES:\n",
    "    SevDB[str('Error_Class_'+str(n))] = one_h_enc[:,i]\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.DataFrame(SevDB[['ImageId','EncodedPixels']])\n",
    "\n",
    "Y_full = pd.DataFrame(SevDB[['Error_Class_1','Error_Class_2','Error_Class_3','Error_Class_4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ErrorClass1: 897.0\n",
      "ErrorClass2: 247.0\n",
      "ErrorClass3: 5150.0\n",
      "ErrorClass4: 801.0\n",
      "total errors: 7095.0\n"
     ]
    }
   ],
   "source": [
    "class1 = Y_full.sum()[0]\n",
    "print('ErrorClass1: ' + str(class1))\n",
    "class2 = Y_full.sum()[1]\n",
    "print('ErrorClass2: ' + str(class2))\n",
    "class3 = Y_full.sum()[2]\n",
    "print('ErrorClass3: ' + str(class3))\n",
    "class4 = Y_full.sum()[3]\n",
    "print('ErrorClass4: ' + str(class4))\n",
    "total = Y_full.sum().sum()\n",
    "print('total errors: ' + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_full,Y_full, test_size=0.2,shuffle=True, random_state=SEED) #SEED\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_full,Y_full, test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT IMGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_IMGS = loadPNGtoArray(X_train['ImageId'],basePath=pathTrainImgs)\n",
    "# X_val_IMGS = loadPNGtoArray(X_val['ImageId'],basePath=pathTrainImgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagePaths= Path('../DB/GC10-DET/images/images/')\n",
    "\n",
    "# # 2048 x 1000\n",
    "\n",
    "# trainset = tf.keras.utils.image_dataset_from_directory(imagePaths,batch_size=32,image_size=(512,512),label_mode='categorical',shuffle=True,seed=SEED,validation_split=0.2,subset='training')\n",
    "# valset = tf.keras.utils.image_dataset_from_directory(imagePaths,batch_size=32,image_size=(512,512),label_mode='categorical',shuffle=True,seed=SEED,validation_split=0.2,subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train_IMGS.shape)\n",
    "# print(X_val_IMGS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.imshow(X_val_IMGS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250798 1 251052 5 251306 8 251560 12 251814 15 252068 19 252322 22 252576 26 252831 28 253087 29 253343 31 253599 32 253855 34 254111 35 254359 1 254367 37 254615 3 254623 38 254872 4 254879 40 255128 5 255135 41 255385 47 255641 47 255898 45 256154 45 256410 45 256667 44 256923 43 257180 42 257436 42 257693 41 257949 40 258205 40 258462 39 258718 39 258975 38 259231 37 259488 36 259744 36 260001 35 260177 3 260257 34 260433 7 260513 34 260689 11 260770 33 260945 15 261026 33 261201 19 261283 31 261456 22 261539 31 261712 24 261796 30 261968 26 262052 30 262224 28 262313 24 262480 30 262579 14 262736 32 262844 5 262992 34 263248 36 263503 38 263759 38 264015 38 264271 37 264527 37 264783 37 265039 37 265295 36 265550 37 265806 37 266062 37 266318 36 266574 36 266830 36 267086 36 267342 35 267597 36 267853 36 268109 36 268365 35 268621 35 268877 35 269133 35 269389 34 269644 35 269900 35 270156 35 270412 34 270668 34 270941 17 395510 2 395763 6 395996 3 396016 9 396252 7 396270 12 396507 12 396523 15 396763 32 397019 33 397274 34 397530 35 397786 36 398041 37 398297 38 398553 38 398808 40 399064 40 399320 40 399575 41 399831 41 400086 42 400342 42 400598 42 400853 43 401109 43 401365 43 401620 44 401876 45 402132 45 402387 46 402643 46 402899 46 403155 46 403410 47 403666 47 403922 47 404178 47 404434 47 404690 47 404945 48 405201 48 405457 48 405713 48 405969 48 406224 49 406480 49 406736 49 406992 49 407248 49 407503 50 407759 50 408015 50 408271 50 408527 50 408783 50 409038 51 409294 51 409550 51\n"
     ]
    }
   ],
   "source": [
    "print(X_full['EncodedPixels'][505])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply segmentation on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "def createMask(imNames, maskPXs, pathOut):\n",
    "    masks = []\n",
    "    for pxs, pt in tqdm(zip(maskPXs,imNames)):\n",
    "        pxs = pxs.split(' ')\n",
    "        # print(pxs)\n",
    "        mask = [0] * IMAGE_SIZE[0] * IMAGE_SIZE[1]\n",
    "        # print(len(mask))\n",
    "        for px,npx in pairwise(pxs):\n",
    "            px = int(px)\n",
    "            npx = int(npx)\n",
    "            # print(int(px))\n",
    "            # print(int(npx))\n",
    "            for i in range(npx):\n",
    "                mask[px-1+i] = 1\n",
    "        \n",
    "        imout = Image.new(mode='1',size=[IMAGE_SIZE[0],IMAGE_SIZE[1]])\n",
    "        imout.putdata(mask)\n",
    "        \n",
    "        imout = imout.rotate(90, expand=1)\n",
    "        imout = imout.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
    "        imout.save(pathOut + pt)\n",
    "        masks.append(imout)\n",
    "        # break\n",
    "\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7095it [00:38, 185.10it/s]\n"
     ]
    }
   ],
   "source": [
    "masks = createMask(X_full['ImageId'],X_full['EncodedPixels'],'../DB/train_images_masks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=1 size=1600x256 at 0x28DAC9297F0>\n"
     ]
    }
   ],
   "source": [
    "print(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0002cc93b.jpg\n"
     ]
    }
   ],
   "source": [
    "print(X_full['ImageId'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28db0f49a00>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(masks[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e7cd14f073366be20c32827cdaa625b7e1180ddc1924692f7e15c6fa4a1924d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorFlowGPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
